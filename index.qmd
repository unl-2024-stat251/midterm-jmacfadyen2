---
title: 251 Midterm Exam
author: Jack Macfadyen
date: '2024-03-07'
execute:
  error: false
categories:
- Exam
- Week07
editor: 
  markdown: 
    wrap: sentence
---

In this exam, you'll be using data collected about US polling places.
The [Center for Public Integrity](https://publicintegrity.org/) assembled this data using open records requests and contact with state or county election officials.
Full documentation is available on the [github repository for the data](https://github.com/PublicI/us-polling-places) - each state's details can be found in a README file for that state; there is also a machine-readable `manifest.yaml` file for each state provided.

We will start out by using data assembled by the TidyTuesday project, but will eventually get to the raw data as well.

The raw CSV data is available at https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-16/polling_places.csv

```{r r-setup}
# load any R packages you use in this chunk
library(dplyr)
library(ggplot2)
library(stringr)
```

```{python py-setup}
# load any python packages you use in this chunk
import pandas as pd
```

# Data Input - Polling Places

(30 pts)

## Data File Inspection

Here are the first six lines of the TidyTuesday CSV file:

```         
election_date,state,county_name,jurisdiction,jurisdiction_type,precinct_id,precinct_name,polling_place_id,location_type,name,address,notes,source,source_date,source_notes
2020-11-03,AL,AUTAUGA,AUTAUGA,county,NA,AUTAUGAVILLE VOL FIRE DEPT,NA,election_day,AUTAUGAVILLE VOL FIRE DEPT,"2610 HIGHWAY 14 W, AUTAUGAVILLE, AL 36003",NA,ORR,2020-10-21,NA
2020-11-03,AL,AUTAUGA,AUTAUGA,county,NA,BILLINGSLEY COMMUNITY CENTER,NA,election_day,BILLINGSLEY COMMUNITY CENTER,"2159 COUNTY RD 37, BILLINGSLEY, AL 36006",NA,ORR,2020-10-21,NA
2020-11-03,AL,AUTAUGA,AUTAUGA,county,NA,BOONE'S CHAPEL,NA,election_day,BOONE'S CHAPEL,"2301 COUNTY RD 66, PRATTVILLE, AL 36067",NA,ORR,2020-10-21,NA
2020-11-03,AL,AUTAUGA,AUTAUGA,county,NA,BOOTH VOL FIRE DEPT,NA,election_day,BOOTH VOL FIRE DEPT,"1701 COUNTY ROAD 10, BOOTH, AL 36008",NA,ORR,2020-10-21,NA
2020-11-03,AL,AUTAUGA,AUTAUGA,county,NA,CAMELLIA BAPTIST CH,NA,election_day,CAMELLIA BAPTIST CH,"201 WOODVALE ROAD, PRATTVILLE, AL 36067",NA,ORR,2020-10-21,NA
```

1.  What is the file delimiter? (1 pt)\

The file delimiter is a comma (',').

2.  What is the header? (1 pt)\

The header is the first row of the file: election_date,state,county_name,jurisdiction,jurisdiction_type,precinct_id,precinct_name, polling_place_id,location_type,name,address,notes,source,source_date,source_notes.

3.  How many columns will the data have when it is read in using R or Python? (1 pt)\

The data will have 15 columns when it is read in, as that is the number of headers in the first row.

4.  How is the data stored differently in the address field compared to the name field (1 pt), and why is this different handling necessary (1 pt)?

The data stored in the address field is more specific than the name field, as it includes things such as the street name/number, zip code, city, and state, whereas the name field only includes the name of the establishment.
This different handling is necessary because it's important to be able to find the exact location for various reasons, such as contacting the establishment or plotting a map of the data.

## Reading the Data

Read in the data in R (5 pts) and in python (5 pts).

Make sure to load any packages which are necessary to run your code in the setup chunks at the beginning of the document.

```{r r-read-data}
data <- read.csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-16/polling_places.csv")
```

```{python py-read-data}
data = pd.read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-16/polling_places.csv", low_memory = False)
```

## Summarize the Data

Using any method you choose from either language, fill in the following table.

Language used: R

Make sure your terms match the language you're using and the code you provided above.
If you use code to get these values (which is probably a good idea), please use the code chunks provided here:

```{r r-data-summary-code}
data_type <- sapply(data, class) # List of variables and the type of data
data_missing_values_count <- sapply(data, function(x) sum(is.na(x))) # List of variables and the amount of null values
data_unique_values_no_missing_count <- sapply(data, function(x) length(unique(x[!is.na(x)]))) # List of variables and the amount of unique values, excluding null values
```

When computing the number of unique values, exclude missing values.

| Column Name       | Data Type (5 pts) | \# missing values (5 pts) | \# unique values (5 pts) |
|------------------|------------------|-------------------|------------------|
| election_date     | Character         | 0                         | 7                        |
| state             | Character         | 0                         | 39                       |
| county_name       | Character         | 114568                    | 1880                     |
| jurisdiction      | Character         | 103599                    | 9206                     |
| jurisdiction_type | Character         | 60                        | 7                        |
| precinct_id       | Character         | 148834                    | 50287                    |
| precinct_name     | Character         | 96860                     | 110887                   |
| polling_place_id  | Character         | 408178                    | 11145                    |
| location_type     | Character         | 192830                    | 6                        |
| name              | Character         | 75                        | 105985                   |
| address           | Character         | 2996                      | 151319                   |
| notes             | Character         | 416312                    | 9614                     |
| source            | Character         | 0                         | 4                        |
| source_date       | Character         | 0                         | 36                       |
| source_notes      | Character         | 425353                    | 4                        |

: Summary of Polling Data

# Data Cleaning - Polling Places over Time

(50 pts)

For this part of the exam, you'll use your student ID to get the state you'll be working with.

```{r student-id-state-assign}
my_nuid <- 56858475
state_ids <- readRDS("state-ids.RDS")
my_state <- state_ids$state[my_nuid%%37]
print(my_state)
```

Your end goal is to get a plot of the number of available polling places in each election, with separate lines for each jurisdiction (e.g. county) within your state.

## Steps

(10 pts)

Write out the steps (in plain language) required to get from the polling place data provided [here](https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-16/polling_places.csv) to the data you need to create your plot.
Make sure to remove polling places which do not make sense - e.g. those with an address consisting of just the state name, or those named "DO NOT USE".

For each step, identify the data manipulation verb you will use, and any variables you will pass in as arguments.
Fill in the following table when you are finished.
Add new rows by moving to a new line, and separate each cell in the table with `|` (spaces matter).
`|` is on the key above the enter key and shares a key with `\` (backslash).
You will need to hold shift down.

| Step \# | Verb      | Arguments                                  | What this does                                                                    |
|---------------|---------------|---------------|----------------------------|
| 1       | filter    | data = data, state == "MT"                 | This filters out all states in the polling data not from Montana                  |
| 2       | filter    | data = data, address != "MT"               | This filters out rows that only have "MT" in their address line                   |
| 3       | group_by  | data = MT_data, election_date, county_name | This groups together all Montana data with the same county name and election date |
| 4       | summarize | num_poll_place = n()                       | This creates a column of the counts of the observations in each group             |

Note: Montana data was manually checked for lines with "DO NOT USE" and there were none.
If there were, the coding function 'grepl' could be used in conjunction with 'filter' to remove any rows that contained "DO NOT USE"

## Code

(10 pts)

Write code in R or python to execute the steps you outlined above.

```{r chart-data}
MT_data <- filter(data, state == "MT")
MT_data <- filter(MT_data, address != "MT")
chart_data <- MT_data %>%
  group_by(election_date, county_name) %>%
  summarize(num_poll_place = n(), .groups = "drop")
```

## Chart Description

(7 pts)

Use the grammar of graphics to identify the components of the chart here, which provides the data for Wisconsin.
![Wisconsin counties where the number of polling places changed, 2012-2020](wisconsin-example.jpg){width="50%"}

-   geom: line

-   aesthetics: (list at least 3)

    -   x = election date, ticks were labelled differently for simplicity

    -   y = number of polling places, ticks become exponentially greater

    -   group = county name, only differentiated by line and not by color, there is no legend

-   coordinate system: cartesian

-   y axis scale: discrete, only whole numbers ranging from less than 10 to over 300, ticks become exponentially greater

-   x axis scale: discrete, dates ranging from 2012 to 2020, ticks were labelled differently for simplicity

## Chart

(20 pts)

Write code in R or python to create a chart like that shown at the beginning of this example (5 pts).
Make sure your axes are labeled (5 pts) and your chart has a title (5 pts).
Include your plot in this document and make sure you have a figure caption that describes what someone should notice in the chart (5 pts) You may do this either by modifying the chunk options or by using `include=F` and manually including the picture with a caption.

```{r}
MT_chart <- ggplot(data = chart_data, aes(x = election_date, y = num_poll_place, group = county_name))+
  geom_line(linewidth = 0.6)+
  labs(x = "Date", y = "Number of Polling Places per County", title = "Montana Polling Place Changes, 2012-2020", caption = "There is a general downward trend of the amount of polling places in Montana, particularly from the year 2012 to 2014.")+
  scale_x_discrete(labels = c("2012", "2014", "2016", "2018", "2020"))
print(MT_chart)
```

## Modifications

Evaluate the chart you created for comprehensibility and accessibility.
(1 pt)

The chart I created is comprehensive and accessible for anyone reading it.
The chart is in black and white, meaning that there's no way people can view the graph differently based on color perception.
The data points are all aligned on the same ticks of the x-axis, making comparisons between the changes of each county easier to read.
The chart title and axes labels give proper context to the data displayed so people are able to appropriately interpret what the data means.
There is no "chartjunk" or extravagant design choices that make the graph difficult to read.

What modifications might you add to this chart to make it clearer and more understandable?
(2 pts)

One modification I could add to the chart to become more understandable is adding an "average" or "total" line to serve as a representation of the general trend data, rather than the reader having to absorb all of the information and interpret the general trend themselves.
Another modification could be changing line thickness based on how many counties have identical data.
This would emphasize how many counties there are that have the same amount of polling places.

# Data Processing

(20 pts)

You want to mail a letter to every polling place in the state you were assigned.
In order to do this, you need to separate out the pieces of the address: building number, street, city, state, and zip code.
Note that not all addresses will have all of these components - in Alaska, for example, there are often not street numbers or even names.

## Function Steps

(5 pts)

Use the following addresses to think through the steps you will need to accomplish this task.

```         
Tatitlek, AK 99677
First Street, Cordova, AK 99574
105 ICE ST, MENASHA, WI 54952-3223
1025 W 5TH AVE, OSHKOSH, WI 54902
1702 COUNTY ROAD 40 W, PRATTVILLE, AL 36067
5281 HIGHWAY 29, CORINTH VFD (PEROTE STATION), BANKS, AL 36005
713 W. MOUNTAIN AVENUE, JACKSONVILLE, AL 36265
COMMUNITY CENTER, 1168 HWY 84, SILAS, AL 36919
```

Write out the steps your function will need to accomplish in plain language.

| Step \# | Verb       | Arguments                                      | What this does                                                                                                                                                                                                        |
|---------------|---------------|---------------|----------------------------|
| 1       | data.frame | building_number = NA, street = NA, etc         | This creates a data frame where we can store the valid address pieces.  |
| 2       | strsplit   | data = address, pattern = ","                  | This breaks apart all of the pieces of the address into chunks. We may have to do this multiple times for some chunks that have separate pieces within them (building number and street address, state and zip code). |
| 3       | grepl      | data = address, pattern = any numerical values | This looks at chunks and sees if they're only made up of numbers. This will be used for zip codes and building numbers.                                                                                               |
| 4       | if         | address_chunks = 1, 2, 3, etc                  | This creates conditions for how long the address is. Different lengths of addresses will need different strategies.  |
| 5       | paste         | address_piece             | This creates conditions for how long the address is. Different lengths of addresses will need different strategies.  |


## Function Code - Single Address

(5 pts)

Write a function, `address_parser`, which can handle a single address and return a data structure containing each piece of the address, with NAs for pieces which are not matched.

(change this chunk to python if you'd prefer to use python over R for this task)

```{r single-address-parser}
address_parser <- function(address){
  # BEGINNING OF MAKING DATA FRAME-----------------------------
  df <- data.frame(
    building_number = NA,
    street = NA,
    city = NA,
    state = NA,
    zip_code = NA,
    stringsAsFactors = FALSE
  )
# END OF MAKING DATA FRAME-----------------------------------
  
  # Identify the chunks
  chunks <- strsplit(address, ",") # This separates every single chunk by comma
  chunks <- lapply(chunks, trimws) # This removes the extra white space of every chunk
  chunks_number <- length(chunks[[1]]) # This counts the amount of chunks, could be useful
  
  # DEALING WITH LAST CHUNK - STATE AND ZIP CODE
  last_chunk <- chunks[[1]][length(chunks[[1]])] # This is the last chunk, usually STATE ZIP
  split_last_chunk <- strsplit(last_chunk, " ") # This is the last chunk split into STATE and ZIP
  df$state <- split_last_chunk[[1]][1] # This stores the first part of last chunk into state
  df$zip_code <- split_last_chunk[[1]][2] # This stores the second part of last chunk into zip_code

  # DEALING WTIH SECOND TO LAST CHUNK - CITY
  second_to_last_chunk <- chunks[[1]][length(chunks[[1]])-1] # This is the second to last chunk  
  df$city <- second_to_last_chunk # This stores the second to last chunk in the city
  
  # DEALING WITH THIRD TO LAST CHUNK
  if (chunks_number == 3){
    third_to_last_chunk <- chunks[[1]][length(chunks[[1]])-2]
    split_third_to_last_chunk <- strsplit(third_to_last_chunk, " ")
    if (all(grepl("^\\d+$", split_third_to_last_chunk[[1]][1]))){
      df$building_number <- split_third_to_last_chunk[[1]][1]
      df$street <- paste(split_third_to_last_chunk[[1]][-1], collapse = " ")
    } else{
      df$street <- third_to_last_chunk
    }
  }
  
  # DEALING WITH FOURTH TO LAST CHUNK
  if (chunks_number == 4){
    third_to_last_chunk <- chunks[[1]][length(chunks[[1]])-2]
    split_third_to_last_chunk <- strsplit(third_to_last_chunk, " ")
    
    fourth_to_last_chunk <- chunks[[1]][length(chunks[[1]])-3]
    split_fourth_to_last_chunk <- strsplit(fourth_to_last_chunk, " ")
    if (all(grepl("^\\d+$", split_third_to_last_chunk[[1]][1]))){
      df$building_number <- split_third_to_last_chunk[[1]][1]
      df$street <- paste(split_third_to_last_chunk[[1]][-1], collapse = " ")
    } else{
      df$building_number <- split_fourth_to_last_chunk[[1]][1]
      df$street <- paste(split_fourth_to_last_chunk[[1]][-1], collapse = " ")
    }
  }

  return(df)
}
```

This chunk will test your function on the addresses provided as examples.
(change this chunk to python if you used python above)

```{r single-address-parser-test, error = T}
address_parser("Tatitlek, AK 99677")
address_parser("First Street, Cordova, AK 99574")
address_parser("105 ICE ST, MENASHA, WI 54952-3223")
address_parser("1025 W 5TH AVE, OSHKOSH, WI 54902")
address_parser("1702 COUNTY ROAD 40 W, PRATTVILLE, AL 36067")
address_parser("5281 HIGHWAY 29, CORINTH VFD (PEROTE STATION), BANKS, AL 36005")
address_parser("713 W. MOUNTAIN AVENUE, JACKSONVILLE, AL 36265")
address_parser("COMMUNITY CENTER, 1168 HWY 84, SILAS, AL 36919")
```

## Function Code - Vector

(5 pts)

Write a function, `address_vec`, which can parse a vector of addresses and return a data frame with columns corresponding to each piece of the address.

(change this chunk to python if you'd prefer to use python over R for this task)

```{r vector-address-parser}
address_vec <- function(addresses) {
  dfs <- list()
  for (address in addresses) {
    parsed_address <- address_parser(address)
    df <- data.frame(parsed_address, stringsAsFactors = FALSE)
    dfs <- c(dfs, list(df))
    combined_dfs <- bind_rows(dfs)
  }
  return(combined_dfs)
}
```

This chunk will test your function on the addresses provided as examples.
Delete whichever chunk corresponds to the language you didn't use.

```{r r-vector-address-parser-test, error = T}
test_vec <- c("Tatitlek, AK 99677", "First Street, Cordova, AK 99574", "105 ICE ST, MENASHA, WI 54952-3223", "1025 W 5TH AVE, OSHKOSH, WI 54902", "1702 COUNTY ROAD 40 W, PRATTVILLE, AL 36067", "5281 HIGHWAY 29, CORINTH VFD (PEROTE STATION), BANKS, AL 36005", "713 W. MOUNTAIN AVENUE, JACKSONVILLE, AL 36265", "COMMUNITY CENTER, 1168 HWY 84, SILAS, AL 36919")
address_vec(test_vec)
```

## Function Evaluation

Use your function to parse a vector of the unique polling place addresses in your state, creating a data table of address components for your letters.
(5 pts)

```{r r-function-eval}
function_evaluation <- address_vec(MT_data$address)
print(function_evaluation[1130:1140,])
```

Where did your function have issues, if it did?
(5 pts)

While there were no problems within the Montana data, the function could have issues if the address line is only one piece long (though, is that really even an address?). It also assumes that the very last piece of the address is the state abbreviation and zip-code, and the second to last piece is the city. If there were any discrepancies with these assumptions, then the output would be incorrect.
